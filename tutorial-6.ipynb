{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d280486-224f-415b-9b1c-6419f6cf5c4f",
   "metadata": {},
   "source": [
    "# Tutorial 6\n",
    "\n",
    "**This tutorial will cover:**\n",
    "\n",
    "* Examples of PySpark MLlib (DataFrame-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f26834-aec3-4657-8ab8-b13c6cfaaf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|Age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Steve| 31|        10| 30000|\n",
      "| Bill| 30|         8| 25000|\n",
      "| John| 29|         4| 20000|\n",
      "| Paul| 24|         3| 20000|\n",
      "|Chris| 21|         1| 15000|\n",
      "|  Tom| 23|         2| 18000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Machine Learning Practice\").getOrCreate()\n",
    "\n",
    "# Read the dataset.\n",
    "dataset = spark.read.csv(\"test-data-6.csv\", header=True, inferSchema=True)\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35792afb-d25c-41a1-bdc2-a6ae58ecb557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the schema.\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f80395a-f04a-4e6d-ab7a-f0b25f200773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experience', 'Salary']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the columns in the dataset.\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6df2f-2bdf-4299-809d-431792b89100",
   "metadata": {},
   "source": [
    "`VectorAssembler` is a transformer that combines a given list of columns into a single vector column. ([MLlib docs](https://spark.apache.org/docs/3.3.1/ml-features.html#vectorassembler)) The columns that are used as inputs and outputs are called \"features\". So you will hear terms like \"feature column\" or \"input features\" or \"independent features\". So the vector column (i.e. output column) is sometimes called an \"input feature\" or \"independent feature\".\n",
    "\n",
    "You will specify the columns that will be used as inputs (i.e. the independent variables or x-variables). \n",
    "Then you will define the output column that will contain the linear regression output (i.e. the dependent variables or the y-variable).\n",
    "\n",
    "The output column will be a vector and the inputs will be used to calculate that vector. \n",
    "In other words, the inputs will be used to \"assemble\" the output vector. Hence the module name `VectorAssembler`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a04543a-20cf-4502-90a7-e55ba3193b31",
   "metadata": {},
   "source": [
    "The following example will show you how to create a model that uses the \"Age\" and \"Experience\" columns to predict the salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d5576f-8b12-4501-a083-ad224ee74da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the VectorAssembler.\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"Age\",\"Experience\"],outputCol=\"Input Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ad9d98-3778-4d25-b8a4-dbf3ef876fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that includes the output column.\n",
    "output = assembler.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a9c87b-8e2c-4eea-9982-c664e0835cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+--------------+\n",
      "| Name|Age|Experience|Salary|Input Features|\n",
      "+-----+---+----------+------+--------------+\n",
      "|Steve| 31|        10| 30000|   [31.0,10.0]|\n",
      "| Bill| 30|         8| 25000|    [30.0,8.0]|\n",
      "| John| 29|         4| 20000|    [29.0,4.0]|\n",
      "| Paul| 24|         3| 20000|    [24.0,3.0]|\n",
      "|Chris| 21|         1| 15000|    [21.0,1.0]|\n",
      "|  Tom| 23|         2| 18000|    [23.0,2.0]|\n",
      "+-----+---+----------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the new dataframe.\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de85bdad-58cd-4da5-9d28-0fa34cc3be6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experience', 'Salary', 'Input Features']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the updated columns in the dataset.\n",
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31851bf8-1c42-448a-ba36-88bf7ad939de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `select()` only the columns that are going to be used when training and testing the data.\n",
    "train_test_df = output.select(\"Input Features\", \"Salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5967cd8-d040-493d-92e3-ece6183bd75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|Input Features|Salary|\n",
      "+--------------+------+\n",
      "|   [31.0,10.0]| 30000|\n",
      "|    [30.0,8.0]| 25000|\n",
      "|    [29.0,4.0]| 20000|\n",
      "|    [24.0,3.0]| 20000|\n",
      "|    [21.0,1.0]| 15000|\n",
      "|    [23.0,2.0]| 18000|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2337879b-cd59-4005-84cf-2ac6333ba77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can train the data in order to be able to predict the salary amounts.\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Create a train, test split. The train dataset will use 75% of the data and the test dataset will have 25% of the data.\n",
    "train_data, test_data = train_test_df.randomSplit([0.75, 0.25])\n",
    "\n",
    "# Create the regression model with the input and output features.\n",
    "regressor = LinearRegression(featuresCol=\"Input Features\", labelCol=\"Salary\")\n",
    "\n",
    "# Fit the model.\n",
    "model = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e80e01ad-a8f4-4c5f-b50a-949f0c7c43c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-263.7076, 1767.624])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficients\n",
    "model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2803b456-8b9b-4c61-8e3e-9e2e977ea59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19919.060052212404"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4442f335-51ae-4b37-afbf-668ecf08f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict salaries.\n",
    "pred_results = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f3fcf50-d9f7-4b1d-97b0-be68731c722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+-----------------+\n",
      "|Input Features|Salary|       prediction|\n",
      "+--------------+------+-----------------+\n",
      "|    [29.0,4.0]| 20000|19342.03655352618|\n",
      "+--------------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the predicted salaries in a dataframe where you can compare the predicted values to the actual salary values.\n",
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f3b2847-6b08-484e-823d-3993ca0571ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(657.9634464738192, 432915.89689570636)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View other important metrics of the predicted values.\n",
    "pred_results.meanAbsoluteError, pred_results.meanSquaredError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
